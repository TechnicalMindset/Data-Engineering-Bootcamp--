{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY7zI+LhE5gQDFEC6sLEV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TechnicalMindset/Data-Engineering-Bootcamp--/blob/main/Web_Scraping_%26_Data_Extraction_with_Python_LAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# ðŸŒŸ Web Scraping & Data Extraction with Python\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ **Introduktion â€“ Vad Ã¤r ETL?**\n",
        "\n",
        "**ETL** stÃ¥r fÃ¶r:\n",
        "\n",
        "- **Extract** â€“ HÃ¤mta data (t.ex. frÃ¥n webbsidor eller API:er) ðŸŒ\n",
        "- **Transform** â€“ Bearbeta datan till ett anvÃ¤ndbart format ðŸ”§\n",
        "- **Load** â€“ Spara datan i en databas eller fil ðŸ“\n",
        "\n",
        "Det anvÃ¤nds ofta i datavetenskap och affÃ¤rsanalys fÃ¶r att samla in, rensa och lagra data frÃ¥n olika kÃ¤llor.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ **LabbmÃ¥l (Objectives)**\n",
        "\n",
        "âœ… Extrahera data frÃ¥n webbsidor och API:er  \n",
        "âœ… LÃ¤sa in data frÃ¥n CSV, JSON och XML  \n",
        "âœ… Transformera datan till enhetligt format  \n",
        "âœ… Spara data i CSV och ladda till en SQLite-databas\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“š **Del 1: Installera nÃ¶dvÃ¤ndiga bibliotek**\n",
        "\n",
        "```python\n",
        "!pip install requests beautifulsoup4 pandas lxml\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ•¸ï¸ **Del 2: Web scraping â€“ Extrahera topp 50 filmer**\n",
        "\n",
        "### ðŸ”½ **Steg 1: Importera bibliotek**\n",
        "\n",
        "```python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”½ **Steg 2: HÃ¤mta webbsidan**\n",
        "\n",
        "```python\n",
        "url = \"https://web.archive.org/web/20230902185655/https://en.everybodywiki.com/100_Most_Highly-Ranked_Films\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Kontrollera att sidan laddades korrekt\n",
        "print(\"Statuskod:\", response.status_code)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”½ **Steg 3: Analysera och extrahera HTML**\n",
        "\n",
        "```python\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Hitta tabellen med filmer\n",
        "table = soup.find(\"table\")\n",
        "\n",
        "# HÃ¤mta alla rader i tabellen (fÃ¶rutom rubrikraden)\n",
        "rows = table.find_all(\"tr\")[1:]\n",
        "\n",
        "# Skapa en lista fÃ¶r att lagra resultaten\n",
        "movies_data = []\n",
        "\n",
        "for row in rows[:50]:  # BegrÃ¤nsa till topp 50\n",
        "    cols = row.find_all(\"td\")\n",
        "    if len(cols) >= 3:\n",
        "        average_rank = cols[0].text.strip()\n",
        "        film = cols[1].text.strip()\n",
        "        year = cols[2].text.strip()\n",
        "        movies_data.append([average_rank, film, year])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”½ **Steg 4: Spara datan i en DataFrame**\n",
        "\n",
        "```python\n",
        "df_movies = pd.DataFrame(movies_data, columns=[\"Average Rank\", \"Film\", \"Year\"])\n",
        "df_movies.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ’¾ **Del 3: Spara till CSV och SQLite**\n",
        "\n",
        "### ðŸ”½ **Spara till CSV-fil**\n",
        "\n",
        "```python\n",
        "df_movies.to_csv(\"top_50_films.csv\", index=False)\n",
        "print(\"âœ… Sparad till top_50_films.csv\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”½ **Spara till SQLite-databas**\n",
        "\n",
        "```python\n",
        "# Skapa anslutning\n",
        "conn = sqlite3.connect(\"Movies.db\")\n",
        "\n",
        "# Spara till tabell \"Top_50\"\n",
        "df_movies.to_sql(\"Top_50\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# BekrÃ¤fta lagring\n",
        "print(\"âœ… Datan har sparats i Movies.db i tabellen 'Top_50'\")\n",
        "\n",
        "# StÃ¤ng anslutningen\n",
        "conn.close()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“„ **Del 4: LÃ¤sa in data frÃ¥n CSV, JSON, XML**\n",
        "\n",
        "### ðŸ”½ **CSV**\n",
        "\n",
        "```python\n",
        "df_csv = pd.read_csv(\"top_50_films.csv\")\n",
        "df_csv.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”½ **JSON (konvertera till JSON fÃ¶rst)**\n",
        "\n",
        "```python\n",
        "df_csv.to_json(\"movies.json\", orient=\"records\", lines=True)\n",
        "\n",
        "# LÃ¤s tillbaka frÃ¥n JSON\n",
        "df_json = pd.read_json(\"movies.json\", lines=True)\n",
        "df_json.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”½ **XML (konvertera till XML)**\n",
        "\n",
        "```python\n",
        "def df_to_xml(df, root_tag=\"Movies\", row_tag=\"Movie\"):\n",
        "    from xml.etree.ElementTree import Element, tostring, SubElement\n",
        "    root = Element(root_tag)\n",
        "    for _, row in df.iterrows():\n",
        "        movie = SubElement(root, row_tag)\n",
        "        for col in df.columns:\n",
        "            child = SubElement(movie, col.replace(\" \", \"\"))\n",
        "            child.text = str(row[col])\n",
        "    return tostring(root, encoding=\"unicode\")\n",
        "\n",
        "# Skapa och spara XML\n",
        "xml_data = df_to_xml(df_csv)\n",
        "with open(\"movies.xml\", \"w\") as f:\n",
        "    f.write(xml_data)\n",
        "\n",
        "print(\"âœ… XML-fil skapad: movies.xml\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  **Slutsats: Vad har vi lÃ¤rt oss?**\n",
        "\n",
        "âœ… Extrahera data frÃ¥n HTML med BeautifulSoup  \n",
        "âœ… Spara och lÃ¤sa data i CSV, JSON och XML  \n",
        "âœ… Transformera data till tabellformat  \n",
        "âœ… Ladda data till SQLite-databas\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VISsnXn2hayo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c59ziNkzhYb5"
      },
      "outputs": [],
      "source": []
    }
  ]
}